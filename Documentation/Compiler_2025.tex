\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}



% Define colors for syntax highlighting
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}

% Configure code listings
\lstset{
    language=TypeScript,
    backgroundcolor=\color{white},
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\title{Judgment Compiler Implementation Documentation}
\author{Ricky Junior Isheja}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Overview}
This document describes the implementation of the judgment compiler written in TypeScript. The lexer's function is to process source code from the language of Alan++ and break it down into a sequence of tokens in order, which eventually will be used by the parser. The parser then takes those tokens and analyses if the given tokens make sense according to the syntax of Alan++. After validating the syntax of the given code we handout the Concrete syntax tree (CST) to the Semantic analyzer which will at the end of the day generate  an Abstract syntax tree (AST) that will help us generate machine readable code. 

\section{Lexer}

The lexer's function is to process source code from the language of Alan++ and break it down into a sequence of ordered tokens, which eventually will be used by the parser. We are able to implement this by designing a number of classes that help us define the language as given so we can either accept the given code or reject it. The following classes help us implement the lexical analysis in the judgment compiler:

\subsection{Token Class}
The \texttt{Token} class represents individual lexical units with the following properties, this is where we initialize the how our tokens will be structured like, for this specific language we only need the type, value and position of the token. This information is what we will be sending to the parser eventually:

\begin{lstlisting}
class Token {
    type: string;       // Type of the token (e.g., 'IDENTIFIER', 'NUMBER')
    value: string | null; // Actual value of the token
    line: number;       // Line number where token appears
    column: number;     // Column number where token appears
}
\end{lstlisting}

\subsection{Lexer Class}
The \texttt{Lexer} class is responsible for tokenizing the input string. In other words this is where we define our language and set what is allowed and what isn't so that the lexer can categorize the tokens and give out relevant information to the programmer:

\begin{lstlisting}
class Lexer {
    input: string;          // Input source code
    position: number;       // Current position in input
    currentChar: string | null; // Current character being processed
    inComment: boolean;     // Flag for comment processing
    errors: string[];       // Collection of lexical errors
    line: number;          // Current line number
    column: number;        // Current column number
}
\end{lstlisting}



\subsubsection{Comment Handling}
The lexer supports multi-line comments using \texttt{/* */} syntax:

\begin{lstlisting}
if (this.currentChar === '/' && this.peek() === '*') {
    this.advance();
    this.advance();
    this.inComment = true;
    this.skipComment();
    continue;
}
\end{lstlisting}

\subsubsection{Error Collection}
\begin{lstlisting}
error(message: string): void {
    this.errors.push(`LEXER --> | Error: ${message} 
        on line ${this.line}:${this.column}`);
    this.advance();
}
\end{lstlisting}

\subsubsection{Position Tracking}
\begin{lstlisting}
advance(): void {
    if (this.currentChar === '\n') {
        this.line++;
        this.column = 0;
    }
    this.position++;
    this.column++;
    this.currentChar = this.input[this.position] || null;
}
\end{lstlisting}

\subsubsection{Keyword Recognition}
The lexer implements a longest-match strategy for keywords:

\begin{lstlisting}
const keywords: { [key: string]: string } = {
    'print': 'PRINT',
    'while': 'WHILE',
    'if': 'IF',
    'int': 'TYPE',
    'string': 'TYPE',
    'boolean': 'TYPE',
    'true': 'BOOLVAL',
    'false': 'BOOLVAL'
};
\end{lstlisting}

\subsubsection{Token Construction}
The lexer first classifies the current character to determine the appropriate token type. Based on the character classification, the lexer calls the appropriate method:
\begin{itemize}
    \item \texttt{identifier()}: For keywords and identifiers
    \item \texttt{number()}: For numeric literals
    \item \texttt{string()}: For string literals
\end{itemize}

The lexer then maintains line and column information for error reporting debugging and future use.

\subsubsection{Program Separation}
The lexer supports multiple programs separated by the '\$' symbol we know that we are at the end of the whole entirety of programs when there are no other details after the EOP. If we end the program and there is no EOP sign we give out a warning stating that we are expecting it:

\begin{lstlisting}
function compile(): void {
    const programs = sourceCode.split('$')
        .filter(prog => prog.trim().length > 0);
    // Process each program separately
}
\end{lstlisting}

\section{Parser}

The parser is responsible for analyzing the sequence of tokens produced by the lexer and determining if they form valid syntax according to the grammar of Alan++. If the syntax is valid, the parser builds a Concrete Syntax Tree (CST) representation of the program.

\subsection{TreeNode Class}
The \texttt{TreeNode} class is the fundamental building block of the Concrete Syntax Tree:

\begin{lstlisting}
class TreeNode {
    name: string;       // Name of the node (e.g., 'Program', 'Block')
    children: TreeNode[]; // Child nodes
    value?: string;     // Optional value for terminal nodes
}
\end{lstlisting}

The \texttt{TreeNode} class provides a method \texttt{addChild} to add child nodes to the tree, facilitating the construction of the hierarchical structure that represents the program's syntax.

\subsection{Parser Class}
The \texttt{Parser} class implements a recursive descent parser that processes tokens according to the grammar rules of Alan++:

\begin{lstlisting}
class Parser {
    private tokens: Token[];           // Input token stream from lexer
    private currentTokenIndex: number; // Current position in token stream
    private errors: string[];          // Collection of parsing errors
    private warnings: string[];        // Collection of warnings
    private cst: TreeNode | null;      // The resulting Concrete Syntax Tree
    private debugCallback?: (message: string) => void; // For debugging output
}
\end{lstlisting}

\subsubsection{Helper Methods}
The Parser implements several helper methods to facilitate the parsing process:

\begin{itemize}
    \item \texttt{getCurrentToken()}: Returns the token at the current position without advancing
    \item \texttt{advance()}: Moves to the next token in the stream
    \item \texttt{addError()}: Records an error message with position information
    \item \texttt{match()}: Checks if the current token matches an expected type and advances if true
    \item \texttt{expect()}: Similar to match but records an error if the token doesn't match
\end{itemize}

\begin{lstlisting}
private expect(expectedType: string, errorMessage: string): boolean {
    if (this.match(expectedType)) {
        return true;
    }
    this.addError(errorMessage);
    return false;
}
\end{lstlisting}

The error handling is particularly detailed, capturing both the error message and the location in the source code:

\begin{lstlisting}
private addError(message: string): void {
    const token = this.getCurrentToken();
    let position = 'end of file';
    
    // Get the position from the current token or the previous token
    if (token && token.type !== 'EOF') {
        position = `line ${token.line}:${token.column}`;
    } else if (this.currentTokenIndex > 0 && this.tokens.length > 0) {
        const lastToken = this.tokens[this.currentTokenIndex - 1];
        position = `line ${lastToken.line}:${lastToken.column}`;
    }
    
    this.errors.push(`PARSER --> Error: ${message} at ${position}`);
    this.debug(`ERROR: ${message} at ${position}`);
}
\end{lstlisting}

\subsubsection{Parsing Methods}
The parser implements a set of methods that correspond to the grammar rules of Alan++. Each method is responsible for parsing a specific syntactic construct:

\begin{itemize}
    \item \texttt{parseProgram()}: Entry point for parsing a complete program
    \item \texttt{parseBlock()}: Parses a block of code enclosed in braces
    \item \texttt{parseStatementList()}: Parses a sequence of statements
    \item \texttt{parseStatement()}: Dispatches to specific statement parsing methods based on token type
    \item \texttt{parsePrintStatement()}, \texttt{parseVarDecl()}, \texttt{parseAssignmentStatement()}, etc.: Parse specific statement types
    \item \texttt{parseExpr()}, \texttt{parseIntExpr()}, \texttt{parseStringExpr()}, \texttt{parseBooleanExpr()}: Parse different types of expressions
\end{itemize}

\subsubsection{Top-Down Parsing Approach}
The parser follows a top-down, recursive descent approach, starting with the program and recursively parsing its components:

\begin{lstlisting}
parseProgram(): TreeNode | null {
    this.debug('Program');
    const programNode = new TreeNode('Program');
    
    // Program ::== Block $
    this.debug('Attempting to parse Block');
    const blockNode = this.parseBlock();
    if (blockNode) {
        programNode.addChild(blockNode);
        this.debug('Block parsed successfully');
        
        this.debug('Expecting EOP ($)');
        if (!this.expect('EOP', "Expected end of program symbol '$'")) {
            this.debug('Failed to find EOP');
            return null;
        }
        this.debug('Found EOP');
        
        this.cst = programNode;
        this.debug('Program parsed successfully');
        return programNode;
    }
    
    this.debug('Failed to parse Program');
    return null;
}
\end{lstlisting}

\subsubsection{Statement Parsing}
The \texttt{parseStatement()} method is particularly important as it determines which type of statement to parse based on the current token:

\begin{lstlisting}
private parseStatement(): TreeNode | null {
    this.debug('Statement');
    const token = this.getCurrentToken();
    this.debug(`Current token: ${token.type} [${token.value}]`);
    
    switch (token.type) {
        case 'PRINT':
            this.debug('Found PRINT statement');
            return this.parsePrintStatement();
        case 'TYPE':
            this.debug('Found TYPE declaration');
            return this.parseVarDecl();
        case 'ID':
            this.debug('Found ID (assignment)');
            return this.parseAssignmentStatement();
        case 'WHILE':
            this.debug('Found WHILE statement');
            return this.parseWhileStatement();
        case 'IF':
            this.debug('Found IF statement');
            return this.parseIfStatement();
        case 'LBRACE':
            this.debug('Found nested block');
            return this.parseBlock();
        default:
            this.debug('No valid statement found');
            return null;
    }
}
\end{lstlisting}

\subsubsection{Expression Parsing}
The parser handles different types of expressions, including integer, string, and boolean expressions:

\begin{lstlisting}
private parseExpr(): TreeNode | null {
    this.debug('Expression');
    const token = this.getCurrentToken();
    this.debug(`Current token: ${token.type} [${token.value}]`);
    
    if (token.type === 'DIGIT') {
        this.debug('Found DIGIT (IntExpr)');
        return this.parseIntExpr();
    }
    if (token.type === 'QUOTE') {
        this.debug('Found QUOTE (StringExpr)');
        return this.parseStringExpr();
    }
    if (token.type === 'LPAREN' || token.type === 'BOOLVAL') {
        this.debug('Found LPAREN or BOOLVAL (BooleanExpr)');
        return this.parseBooleanExpr();
    }
    if (token.type === 'ID') {
        this.debug('Found ID');
        this.advance();
        this.debug('ID parsed successfully');
        return new TreeNode('Id', token.value || '');
    }
    
    this.debug('No valid expression found');
    return null;
}
\end{lstlisting}

\subsection{Concrete Syntax Tree Visualization}
The Parser provides a method to visualize the CST with color-coded formatting:

\begin{lstlisting}
public static visualizeTree(node: TreeNode, indent: string = ''): string {
    const nodeColor = '#FFA500'; // Orange for node names
    const valueColor = '#6A8759'; // Green for values
    const indentColor = '#606366'; // Grey for indent lines

    let result = `<span style="color: ${indentColor}">${indent}</span>`;
    result += `<span style="color: ${nodeColor}">${node.name}</span>`;
    
    if (node.value) {
        result += `<span style="color: ${valueColor}"> [${node.value}]</span>`;
    }
    result += '\n';

    for (const child of node.children) {
        result += Parser.visualizeTree(child, indent + '  ');
    }
    return result;
}
\end{lstlisting}

\subsection{Debugging Support}
The parser includes comprehensive debugging support to aid in understanding the parsing process:

\begin{lstlisting}
public enableDebug(callback: (message: string) => void): void {
    this.debugCallback = callback;
}

private debug(message: string): void {
    if (this.debugCallback) {
        this.debugCallback(message);
    }
}
\end{lstlisting}

Debug messages are emitted at each step of the parsing process, providing visibility into the parser's decision-making and progress.

\subsection{Compilation Process}
The \texttt{compile()} function orchestrates the entire compilation process, it does this by following the steps below:
\begin{itemize}
    \item Splits input code into separate programs based on the \$ (EOP) delimiter
    \item Processes each program individually
    \item Performs lexical analysis first, collecting tokens
    \item Only proceeds to parsing if lexical analysis succeeds
    \item Enables debugging for the parser to provide detailed parsing information
    \item Visualizes the resulting CST if parsing succeeds
    \item Captures and displays any errors that occur during compilation
\end{itemize}

\subsection{Error Recovery}
The parser employs a simple error recovery strategy:
\begin{itemize}
    \item When an error is encountered during parsing, the error is recorded with detailed position information
    \item The parser may attempt to continue parsing in some cases, but returns null for the current construct if recovery isn't possible
    \item Higher-level parsing methods check for null returns from lower-level methods to propagate errors upward
\end{itemize}

This approach allows the parser to detect multiple errors in a single pass while still providing meaningful feedback about each error's location and nature.

\section{Semantic Analyser}

The semantic analyser takes the Concrete Syntax Tree (CST) produced by the parser and performs semantic checking to ensure the program is meaningful according to the language rules. It builds an Abstract Syntax Tree (AST) which represents the semantic structure of the program and maintains a symbol table to track variable declarations, scopes, and usage patterns.

\subsection{Symbol Table}
The \texttt{SymbolTable} class is a crucial component that tracks variable declarations across different scopes:

\begin{lstlisting}
class SymbolTable {
    private symbols: Map<string, SymbolTableEntry>;
    private parent: SymbolTable | null;
    private scopeLevel: number;
    private children: SymbolTable[];
}
\end{lstlisting}

The symbol table uses a hierarchical structure to represent nested scopes:

\begin{itemize}
    \item Each scope maintains its own collection of variable declarations
    \item Child scopes can access symbols from parent scopes
    \item The global scope is at level 0, with nested scopes incrementing by 1
    \item Symbol lookups check the current scope first, then traverse up the parent chain
    \item Each variable tracks initialization and usage status
\end{itemize}

\subsubsection{Symbol Table Entry}
Each entry in the symbol table contains detailed information about a variable:

\begin{lstlisting}
interface SymbolTableEntry {
    name: string;
    type: string;
    isInitialized: boolean;
    isUsed: boolean;
    line: number;
    column: number;
}
\end{lstlisting}

\subsubsection{Scope Management}
The symbol table provides methods for creating and navigating nested scopes:

\begin{lstlisting}
// Create a new nested scope
enterScope(): SymbolTable {
    return new SymbolTable(this);
}

// Return to parent scope
exitScope(): SymbolTable | null {
    return this.parent;
}
\end{lstlisting}

This allows the semantic analyser to maintain proper variable visibility rules as it processes different blocks of code.

\subsection{Semantic Analyser Class}
The \texttt{SemanticAnalyser} class performs the semantic analysis:

\begin{lstlisting}
class SemanticAnalyser {
    private tokens: Token[];
    private currentTokenIndex: number;
    private errors: string[];
    private warnings: string[];
    private symbolTable: SymbolTable;
    private currentScope: SymbolTable;
    private ast: ASTNode | null;
    private hints: { message: string; line: number; column: number }[];
    private scopeStack: SymbolTable[];
}
\end{lstlisting}

\subsubsection{AST Node Structure}
The semantic analyser builds an Abstract Syntax Tree (AST) using this node structure:

\begin{lstlisting}
interface ASTNode {
    type: string;
    value?: string;
    children: ASTNode[];
    line?: number;
    column?: number;
}
\end{lstlisting}

Unlike the CST, the AST removes unnecessary syntactic details and retains only semantically relevant nodes.

\subsubsection{Analysis Process}
The semantic analysis follows a structured approach:

\begin{lstlisting}
analyzeProgram(): ASTNode | null {
    // Create program node
    const programNode: ASTNode = {
        type: 'Program',
        children: []
    };

    // Analyze the block
    const blockNode = this.analyzeBlock(false);
    if (blockNode) {
        programNode.children.push(blockNode);
    }

    // Check for end of program
    if (this.getCurrentToken().type !== 'EOP') {
        this.addError("Expected end of program symbol '$'", 
            this.getCurrentToken().line, 
            this.getCurrentToken().column);
        return null;
    }

    // Check for unused variables
    this.checkUnusedVariables();

    this.ast = programNode;
    return programNode;
}
\end{lstlisting}

\subsubsection{Type Checking}
The analyser performs type checking for expressions and assignments:

\begin{lstlisting}
// Type checking - normalize types
if (symbol) {
    const expectedType = symbol.type.toLowerCase();
    const actualType = exprNode.type.toLowerCase();
    
    if (expectedType === 'int' && (actualType === 'intexpr' || actualType === 'digit')) {
        // This is valid
    }
    else if (expectedType === 'string' && actualType === 'stringexpr') {
        // This is valid
    }
    else if (expectedType === 'boolean' && (actualType === 'boolexpr' || actualType === 'boolval')) {
        // This is valid
    }
    else if (expectedType === actualType) {
        // This is valid
    }
    else {
        this.addError(`Type mismatch: cannot assign ${actualType} to ${expectedType}`, 
            idToken.line, 
            idToken.column);
    }
}
\end{lstlisting}

\subsubsection{Error Handling and Warnings}
The semantic analyser provides comprehensive error reporting and helpful hints:

\begin{lstlisting}
private addError(message: string, line: number, column: number): void {
    this.errors.push(`SEMANTIC --> Error: ${message} at line ${line}:${column}`);
    this.debug(`ERROR: ${message} at line ${line}:${column}`);
}

private addWarning(message: string, line: number, column: number): void {
    this.warnings.push(`SEMANTIC --> Warning: ${message} at line ${line}:${column}`);
    this.debug(`WARNING: ${message} at line ${line}:${column}`);
}

private addHint(message: string, line: number, column: number) {
    this.hints.push({
        message,
        line,
        column
    });
}
\end{lstlisting}

\subsubsection{Static Analysis}
The analyser performs static checks such as identifying:

\begin{itemize}
    \item Variables used before initialization
    \item Unused variables
    \item Type mismatches in expressions and assignments
    \item Potential infinite loops
\end{itemize}

\begin{lstlisting}
// Check for unused variables
private checkUnusedVariables(): void {
    const unusedSymbols = this.symbolTable.getUnusedSymbols();
    
    for (const { symbol, scopeLevel } of unusedSymbols) {
        this.addWarning(`Variable '${symbol.name}' is declared but never used`, 
            symbol.line, 
            symbol.column);
        this.addHint(`Consider removing the unused variable or using it in your code`, 
            symbol.line, 
            symbol.column);
    }
}
\end{lstlisting}

\subsection{Context-Sensitive Analysis}
Unlike the lexer and parser which perform context-free analysis, the semantic analyser performs context-sensitive analysis, examining:

\begin{itemize}
    \item Variable declarations and their scopes
    \item Type compatibility in expressions and assignments
    \item Control flow structures like if statements and while loops
    \item Boolean expressions and comparisons
\end{itemize}

\subsection{AST Visualization}
The semantic analyser provides methods to visualize the Abstract Syntax Tree:

\begin{lstlisting}
public static visualizeTree(node: ASTNode | null): string {
    if (node === null) {
        return "AST is null";
    }
    
    return "AST:\n" + this.visualizeTreeNode(node);
}

private static visualizeTreeNode(node: ASTNode, indent: string = ""): string {
    let result = indent + node.type;
    
    if (node.value !== undefined) {
        result += ` [${node.value}]`;
    }
    result += "\n";
    
    for (const child of node.children) {
        result += this.visualizeTreeNode(child, indent + "  ");
    }
    
    return result;
}
\end{lstlisting}

\subsection{Symbol Table Visualization}
The semantic analyser can also generate a visual representation of the symbol table:

\begin{lstlisting}
public static visualizeSymbolTable(symbols: { name: string; type: string; initialized: boolean; isUsed: boolean; line: number; column: number; scopeLevel: number }[]): string {
    // Group symbols by scope level
    const symbolsByScope: Record<number, typeof symbols> = {};
    symbols.forEach(symbol => {
        if (!symbolsByScope[symbol.scopeLevel]) {
            symbolsByScope[symbol.scopeLevel] = [];
        }
        symbolsByScope[symbol.scopeLevel].push(symbol);
    });
    
    let output = "SYMBOL TABLE\n============\n\n";
    
    // Process each scope level
    Object.keys(symbolsByScope).map(Number).sort((a, b) => a - b).forEach(level => {
        const scopeSymbols = symbolsByScope[level].sort((a, b) => a.name.localeCompare(b.name));
        
        output += `Scope Level ${level}${level === 0 ? " (Global)" : ""}\n`;
        output += "─".repeat(60) + "\n";
        
        // Add symbols for this scope with their properties
        scopeSymbols.forEach(symbol => {
            const initialized = symbol.initialized ? "Yes" : "No";
            const used = symbol.isUsed ? "Yes" : "No";
            
            output += symbol.name.padEnd(15) + "│ " + 
                     symbol.type.padEnd(10) + "│ " + 
                     initialized.padEnd(5) + "│ " + 
                     used.padEnd(5) + "│ " + 
                     `${symbol.line}:${symbol.column}\n`;
        });
    });
    
    return output;
}
\end{lstlisting}

\subsection{Integration with Compilation Pipeline}
The semantic analyser integrates into the compilation pipeline after the parser:

\begin{lstlisting}
// If parsing succeeded, proceed with semantic analysis
const semanticAnalyzer = new SemanticAnalyser(tokens);
semanticAnalyzer.enableDebug((msg) => {
    output += `<div style="color: #666; margin-left: 20px;">SEMANTIC --> ${msg}</div>`;
});
const ast = semanticAnalyzer.analyzeProgram();

// Display error messages if any
if (semanticAnalyzer.getErrors().length > 0) {
    output += semanticAnalyzer.getErrors().map(error => 
        `<div style="color: red; font-weight: bold;">${error}</div>`).join('');
    output += `<div style="color: red; font-weight: bold;">Semantic analysis failed</div>`;
} else {
    // Display semantic warnings and hints if any
    if (semanticAnalyzer.getWarnings().length > 0) {
        output += semanticAnalyzer.getWarnings().map(warning => 
            `<div style="color: #FFB100; font-weight: bold;">${warning}</div>`).join('');
    }
    // Display AST visualization
    output += `<div style="color: #4CAF50; font-weight: bold;">Semantic analysis completed successfully</div>`;
    output += `<h4>Abstract Syntax Tree</h4>`;
    output += `<pre>${SemanticAnalyser.visualizeTree(ast)}</pre>`;
}
\end{lstlisting}

\section{Artificial Intelligence Transcripts}
While building this project I used the help of cursor and the 3.5 sonnet model. I tried out a couple of scripts and I meta-prompted with OpenAI model GPT-4: 
\subsection{Lexer AI Prompt}
Write a TypeScript lexer that tokenizes source code into different token types. The lexer should include a Token class to store token type, value, line, and column. Implement a Lexer class with methods to: 
\begin{itemize}
    \item \ Track the current position in the input, line, and column numbers.
    \item \ Handle whitespace, comments (/.../), and strings (enclosed in double quotes).
    \item \ Recognize keywords (print, while, if, int, string, boolean, true, false).
    \item \ Identify identifiers, digits, and special characters ({}, (), +, =, ==, !=).
    \item \ Report errors for invalid characters.
    \item \ Format token output and provide a program status summary.
\end{itemize}
Refer to the language attached and Include a compile() function that integrates the lexer with an HTML interface, reading source code from a textarea and displaying tokenized output in a div.

\subsection{Parser AI Prompt}
Write a TypeScript implementation of a simple parser that builds a Concrete Syntax Tree (CST) from a list of tokens: 
\begin{itemize}
    \item \ The CST should be represented using a TreeNode class with a name, children, and an optional value.
    \item \ The parser should have methods to process a Program, Block, StatementList, and various types of statements (PrintStatement, VarDecl, AssignmentStatement, WhileStatement, IfStatement).
    \item \ It should include error handling, logging debug messages, and a mechanism for matching and expecting tokens.
    \item \ The parser should take a list of tokens as input and traverse them systematically.
    \item \ Implement helper functions to get the current token, advance through tokens, and generate errors and warnings when necessary.
\end{itemize}

\end{document}